{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as prep\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、工具类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数初始化器\n",
    "def xavier_init(fan_in, fan_out, constant = 1):\n",
    "    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out),\n",
    "                             minval = low, maxval = high,\n",
    "                             dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、编码模型类*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveGaussianNoiseAutoencoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus, optimizer = tf.train.AdamOptimizer(),\n",
    "                 scale = 0.1):\n",
    "        self.n_input = n_input    #输入节点数\n",
    "        self.n_hidden = n_hidden  #隐藏层节点数\n",
    "        self.transfer = transfer_function  #激活函数\n",
    "        self.scale = tf.placeholder(tf.float32)   \n",
    "        self.training_scale = scale   #高斯噪声系数\n",
    "        network_weights = self._initialize_weights()   #参数初始化（使用到之前的工具类）\n",
    "        self.weights = network_weights\n",
    "\n",
    "        # model\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        #计算隐藏层\n",
    "        self.hidden = self.transfer(tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)),\n",
    "                self.weights['w1']),\n",
    "                self.weights['b1']))\n",
    "        #计算输出层，因为自编码器要求输出与输入一样，所以不是output而是reconstruction\n",
    "        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n",
    "\n",
    "        # cost，输入与输出的均方误差\n",
    "        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "\n",
    "        #创建类的时候就初始化参数了\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    #初始化参数的方法\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.Variable(xavier_init(self.n_input, self.n_hidden))\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype = tf.float32))\n",
    "        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype = tf.float32))\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype = tf.float32))\n",
    "        return all_weights\n",
    "    \n",
    "    #实际开始运行优化的函数\n",
    "    def partial_fit(self, X):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict = {self.x: X,\n",
    "                                                                            self.scale: self.training_scale\n",
    "                                                                            })\n",
    "        return cost\n",
    "\n",
    "    #不优化，只输出cost值\n",
    "    def calc_total_cost(self, X):\n",
    "        return self.sess.run(self.cost, feed_dict = {self.x: X,\n",
    "                                                     self.scale: self.training_scale\n",
    "                                                     })\n",
    "\n",
    "    #运行子图，获取隐藏层\n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.hidden, feed_dict = {self.x: X,\n",
    "                                                       self.scale: self.training_scale\n",
    "                                                       })\n",
    "\n",
    "    #运行子图，输入隐藏层获取到的输出层（因为输出层只需要hidden）\n",
    "    def generate(self, hidden = None):\n",
    "        if hidden is None:\n",
    "            hidden = np.random.normal(size = self.weights[\"b1\"])\n",
    "        return self.sess.run(self.reconstruction, feed_dict = {self.hidden: hidden})\n",
    "\n",
    "    #完整运行graph，获取输出值，=transform+generate\n",
    "    def reconstruct(self, X):\n",
    "        return self.sess.run(self.reconstruction, feed_dict = {self.x: X,\n",
    "                                                               self.scale: self.training_scale\n",
    "                                                               })\n",
    "    #获取隐藏层的w参数\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "    \n",
    "    #获取隐藏层的b参数\n",
    "    def getBiases(self):\n",
    "        return self.sess.run(self.weights['b1'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、读取mnist数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#换成你自己的路径\n",
    "mnist = input_data.read_data_sets('../datasets/MNIST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、又有俩工具类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(X_train, X_test):\n",
    "    #使用sklearn的函数进行预处理标准化\n",
    "    preprocessor = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "#从数据集中随机获取一个batch集\n",
    "def get_random_block_from_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index:(start_index + batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、终于开始训练、验证数据了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据标准化,实际上就是把图片的三维压缩成了一维，然后归一化\n",
    "X_train, X_test = standard_scale(mnist.train.images, mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(55000, 784)\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.00461458\n",
      " -0.00601082 -0.00426409 -0.00426409  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.00426406\n",
      " -0.00491916 -0.00919097 -0.01148822 -0.01441607 -0.01938349 -0.02483363\n",
      " -0.02953284 -0.03112361 -0.03167421 -0.03243978 -0.0299217  -0.03101258\n",
      " -0.02862023 -0.02337851 -0.01906476 -0.01635208 -0.01011273]\n"
     ]
    }
   ],
   "source": [
    "print type(X_train)\n",
    "print X_train.shape\n",
    "print X_train[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一些常量\n",
    "NUM = int(mnist.train.num_examples)\n",
    "EPOCHES = 20  \n",
    "BATCH_size = 128\n",
    "DISPLAY_step = 1  #每隔多少轮显示一次cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建模型实例，构造方法中已初始化好了变量\n",
    "autoencoder = AdditiveGaussianNoiseAutoencoder(n_input = 784,\n",
    "                                               n_hidden = 200,\n",
    "                                               transfer_function = tf.nn.softplus,\n",
    "                                               optimizer = tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                                               scale = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 12225.142872727\n",
      "Epoch: 0002 cost= 9826.498107386\n",
      "Epoch: 0003 cost= 10504.222054545\n",
      "Epoch: 0004 cost= 10482.087984091\n",
      "Epoch: 0005 cost= 8570.788173295\n",
      "Epoch: 0006 cost= 8531.979227273\n",
      "Epoch: 0007 cost= 10063.344133523\n",
      "Epoch: 0008 cost= 8457.045868750\n",
      "Epoch: 0009 cost= 8833.006449432\n",
      "Epoch: 0010 cost= 8322.703061364\n",
      "Epoch: 0011 cost= 8506.528192614\n",
      "Epoch: 0012 cost= 8027.122040909\n",
      "Epoch: 0013 cost= 8373.752133523\n",
      "Epoch: 0014 cost= 8313.309917614\n",
      "Epoch: 0015 cost= 8298.272556250\n",
      "Epoch: 0016 cost= 7705.873556818\n",
      "Epoch: 0017 cost= 7880.898230114\n",
      "Epoch: 0018 cost= 8159.548758523\n",
      "Epoch: 0019 cost= 7532.065497727\n",
      "Epoch: 0020 cost= 7927.166675568\n",
      "Total cost: 697277.0\n"
     ]
    }
   ],
   "source": [
    "# 开始迭代训练epoch轮\n",
    "for epoch in range(EPOCHES):\n",
    "    avg_cost = 0.\n",
    "    # 每轮要训练多少个batch\n",
    "    total_batch = int(NUM / BATCH_size)\n",
    "    \n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        # 随机从训练集中获取一个batch\n",
    "        batch_xs = get_random_block_from_data(X_train, BATCH_size)\n",
    "        \n",
    "        # Fit training using batch data\n",
    "        # 训练这个batch\n",
    "        cost = autoencoder.partial_fit(batch_xs)\n",
    "        \n",
    "        # Compute average loss\n",
    "        avg_cost += cost / NUM * BATCH_size\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % DISPLAY_step == 0:\n",
    "        print \"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "print \"Total cost: \" + str(autoencoder.calc_total_cost(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09321236  0.09074684  0.05463809 ...,  0.00169099 -0.03547013\n",
      "   0.06860419]\n",
      " [-0.01404193 -0.03381761  0.05111738 ...,  0.05779494  0.03069022\n",
      "  -0.05018943]\n",
      " [ 0.1076509  -0.04194646 -0.08686957 ...,  0.0378673  -0.08989307\n",
      "  -0.0800903 ]\n",
      " ..., \n",
      " [-0.11409521 -0.04100924  0.04975993 ...,  0.06152834  0.05778983\n",
      "  -0.03277344]\n",
      " [-0.026313    0.04970432  0.00394098 ...,  0.07307377 -0.09624624\n",
      "   0.02843025]\n",
      " [ 0.02273075  0.04412144 -0.03265305 ...,  0.01932362  0.01018522\n",
      "  -0.06205586]]\n"
     ]
    }
   ],
   "source": [
    "#获取训练完成后的权重\n",
    "print autoencoder.getWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
